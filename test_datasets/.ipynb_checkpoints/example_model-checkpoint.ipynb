{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Example classifier on Numerai data using a logistic regression classifier.\n",
    "To get started, install the required packages: pip install pandas, numpy, sklearn\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing, linear_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(0)\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    # Load the data from the CSV files\n",
    "    ''' training data contains only training data'''\n",
    "    training_data = pd.read_csv('in/numerai_training_data.csv', header=0)\n",
    "    '''\n",
    "    prediction_data contains both validation data (with targets) and test data\n",
    "    (without targets)\n",
    "    '''\n",
    "    prediction_data = pd.read_csv('in/numerai_tournament_data.csv', header=0)\n",
    "\n",
    "    # print('\\n')\n",
    "    # print('prediction_data')\n",
    "    # print(prediction_data)\n",
    "\n",
    "\n",
    "    # Transform the loaded CSV data into numpy arrays\n",
    "    '''\n",
    "    Goes through all the pd.DataFrame columns titles. If they contain 'feature'\n",
    "    they are added to the features list\n",
    "    '''\n",
    "    features = [f for f in list(training_data) if \"feature\" in f]\n",
    "    X = training_data[features]                     # pd.DataFrame of all training features\n",
    "    Y = training_data[\"target\"]                     # pd.Series of the classes\n",
    "    x_prediction = prediction_data[features]        # pd.DataFrame of all validation and test features\n",
    "    ids = prediction_data[\"id\"]\n",
    "    print('\\n')\n",
    "    print('ids')\n",
    "    print(ids)\n",
    "    print('\\n')\n",
    "    print('ids')\n",
    "    print(ids.duplicated)\n",
    "\n",
    "    # This is your model that will learn to predict\n",
    "    model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    # Your model is trained on the training_data\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    # Your trained model is now used to make predictions on the numerai_tournament_data\n",
    "    # The model returns two columns: [probability of 0, probability of 1]\n",
    "    # We are just interested in the probability that the target is 1.\n",
    "    y_prediction = model.predict_proba(x_prediction)\n",
    "    results = y_prediction[:, 1]\n",
    "    results_df = pd.DataFrame(data={'probability':results})\n",
    "    joined = pd.DataFrame(ids).join(results_df)\n",
    "\n",
    "    print(\"Writing predictions to predictions.csv\")\n",
    "    # Save the predictions out to a CSV file\n",
    "    joined.to_csv(\"predictions.csv\", index=False)\n",
    "    # Now you can upload these predictions on numer.ai\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "project = 'test_datasets'\n",
    "\n",
    "import os.path\n",
    "import sys\n",
    "current_dir = os.path.abspath('./')\n",
    "project_dir = current_dir[:current_dir.rfind(project)+len(project)+1]\n",
    "sys.path.insert(0, project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('in/numerai_training_data.csv', header=0)\n",
    "prediction_data = pd.read_csv('in/numerai_tournament_data.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, feature_extraction, feature_selection, model_selection, metrics\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "# import utils\n",
    "# from classes import ML\n",
    "\n",
    "\n",
    "class ML(object):\n",
    "    def __init__(self, df=None, x_columns=None, y_column=None, convert_dict=None,\n",
    "                 drop_dict=None, replace_dict=None, feature_dict=None,\n",
    "                 method=None, model_params={}, *args, **kwargs):\n",
    "        super(ML, self).__init__()\n",
    "        self.df = df\n",
    "        self.x_columns = x_columns\n",
    "        self.y_column = y_column\n",
    "        self.convert_dict = convert_dict\n",
    "        self.drop_dict = drop_dict\n",
    "        self.replace_dict = replace_dict\n",
    "        self.feature_dict = feature_dict\n",
    "        self.method = method\n",
    "        self.model_params = model_params\n",
    "        \n",
    "        self.n_columns = len(self.df.columns)-2\n",
    "\n",
    "    def convert(self):\n",
    "        if self.convert_dict is not None:\n",
    "            for column, func in self.convert_dict.items():\n",
    "                self.df[column] = func(self.df[column])\n",
    "\n",
    "    def feature(self):\n",
    "        '''call feature building functions on columns'''\n",
    "        for column, func in self.feature_dict.items():\n",
    "            self.df[column] = func(self.df)\n",
    "\n",
    "    def save_mapping(self):\n",
    "        pass\n",
    "\n",
    "    def load_mapping(self):\n",
    "        pass\n",
    "\n",
    "    def get_X(self, sparse=True):\n",
    "        self.vectorizer_ = feature_extraction.DictVectorizer(sparse=sparse)\n",
    "        self.X = self.vectorizer_.fit_transform(self.df[self.x_columns].to_dict(orient='records'))\n",
    "        self.feature_columns_ = self.vectorizer_.vocabulary_\n",
    "\n",
    "    def get_y(self):\n",
    "        self.y = np.array(self.df[self.y_column])\n",
    "\n",
    "    def create_model(self, method=None, model_params=None):\n",
    "        if method:\n",
    "            self.method = method\n",
    "        \n",
    "        if model_params:\n",
    "            self.model_params = model_params\n",
    "\n",
    "        if self.method == 'classification':\n",
    "            if model_params:\n",
    "                self.model = xgb.XGBClassifier(**self.model_params)\n",
    "            else:\n",
    "                self.model = xgb.XGBClassifier()\n",
    "        elif self.method == 'regression':\n",
    "            print('Not implemented yet')\n",
    "\n",
    "    def train(self):\n",
    "        self.model.fit(self.X, self.y)\n",
    "        \n",
    "    def cross_val(self):\n",
    "        pass\n",
    "\n",
    "    def pickle(self):\n",
    "        pass\n",
    "\n",
    "    def unpickle(self):\n",
    "        pass\n",
    "\n",
    "    def score(self):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_features = len(training_data.columns)-3\n",
    "x_columns = ['feature'+str(i) for i in range(1,num_features)]\n",
    "y_column = 'target'\n",
    "\n",
    "drop_dict = {}\n",
    "replace_dict = {}\n",
    "convert_dict = {'created': pd.to_datetime,\n",
    "                     'planned_installation_time': pd.to_numeric,\n",
    "                     'status_type': pd.to_numeric}\n",
    "\n",
    "def get_end_of_month(df):\n",
    "    return df['created'].dt.is_month_end\n",
    "\n",
    "\n",
    "feature_dict = {'month_end': get_end_of_month}\n",
    "\n",
    "ml = ML(df=training_data, \n",
    "           x_columns=x_columns,\n",
    "           y_column=y_column,\n",
    "           drop_dict=drop_dict,\n",
    "           replace_dict=replace_dict,\n",
    "           convert_dict=convert_dict,\n",
    "           feature_dict=feature_dict)\n",
    "ml.get_X()\n",
    "ml.get_y()\n",
    "# ml.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ml.create_model(method='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ml.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = ml.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = model.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# unique index\n",
    "df['id'].nunique()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(model.n_columns):\n",
    "    print('feature'+str(i+1))\n",
    "    df.sort_values(by='id').plot(kind='line', x='id', y='feature'+str(i+1))\n",
    "    df.plot(x=df.index, y='feature'+str(i+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
