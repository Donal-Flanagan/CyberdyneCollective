{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Example classifier on Numerai data using a logistic regression classifier.\n",
    "To get started, install the required packages: pip install pandas, numpy, sklearn\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, preprocessing, linear_model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(0)\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    # Load the data from the CSV files\n",
    "    ''' training data contains only training data'''\n",
    "    training_data = pd.read_csv('in/numerai_training_data.csv', header=0)\n",
    "    '''\n",
    "    prediction_data contains both validation data (with targets) and test data\n",
    "    (without targets)\n",
    "    '''\n",
    "    prediction_data = pd.read_csv('in/numerai_tournament_data.csv', header=0)\n",
    "\n",
    "    # print('\\n')\n",
    "    # print('prediction_data')\n",
    "    # print(prediction_data)\n",
    "\n",
    "\n",
    "    # Transform the loaded CSV data into numpy arrays\n",
    "    '''\n",
    "    Goes through all the pd.DataFrame columns titles. If they contain 'feature'\n",
    "    they are added to the features list\n",
    "    '''\n",
    "    features = [f for f in list(training_data) if \"feature\" in f]\n",
    "    X = training_data[features]                     # pd.DataFrame of all training features\n",
    "    Y = training_data[\"target\"]                     # pd.Series of the classes\n",
    "    x_prediction = prediction_data[features]        # pd.DataFrame of all validation and test features\n",
    "    ids = prediction_data[\"id\"]\n",
    "    print('\\n')\n",
    "    print('ids')\n",
    "    print(ids)\n",
    "    print('\\n')\n",
    "    print('ids')\n",
    "    print(ids.duplicated)\n",
    "\n",
    "    # This is your model that will learn to predict\n",
    "    model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    # Your model is trained on the training_data\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    # Your trained model is now used to make predictions on the numerai_tournament_data\n",
    "    # The model returns two columns: [probability of 0, probability of 1]\n",
    "    # We are just interested in the probability that the target is 1.\n",
    "    y_prediction = model.predict_proba(x_prediction)\n",
    "    results = y_prediction[:, 1]\n",
    "    results_df = pd.DataFrame(data={'probability':results})\n",
    "    joined = pd.DataFrame(ids).join(results_df)\n",
    "\n",
    "    print(\"Writing predictions to predictions.csv\")\n",
    "    # Save the predictions out to a CSV file\n",
    "    joined.to_csv(\"predictions.csv\", index=False)\n",
    "    # Now you can upload these predictions on numer.ai\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "project = 'test_datasets'\n",
    "\n",
    "import os.path\n",
    "import sys\n",
    "current_dir = os.path.abspath('./')\n",
    "project_dir = current_dir[:current_dir.rfind(project)+len(project)+1]\n",
    "sys.path.insert(0, project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('in/numerai_training_data.csv', header=0)\n",
    "prediction_data = pd.read_csv('in/numerai_tournament_data.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, feature_extraction, feature_selection, model_selection, metrics\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "# import utils\n",
    "# from classes import ML\n",
    "\n",
    "\n",
    "class ML(object):\n",
    "    def __init__(self, df=None, x_columns=None, y_column=None, convert_dict=None,\n",
    "                 drop_dict=None, replace_dict=None, feature_dict=None,\n",
    "                 method=None, model_params={}, *args, **kwargs):\n",
    "        super(ML, self).__init__()\n",
    "        self.df = df\n",
    "        self.x_columns = x_columns\n",
    "        self.y_column = y_column\n",
    "        self.convert_dict = convert_dict\n",
    "        self.drop_dict = drop_dict\n",
    "        self.replace_dict = replace_dict\n",
    "        self.feature_dict = feature_dict\n",
    "        self.method = method\n",
    "        self.model_params = model_params\n",
    "        self.sample_weight=None\n",
    "        self.eval_metric=None\n",
    "        \n",
    "        self.n_columns = len(self.df.columns)-2\n",
    "\n",
    "    def convert(self):\n",
    "        if self.convert_dict is not None:\n",
    "            for column, func in self.convert_dict.items():\n",
    "                self.df[column] = func(self.df[column])\n",
    "\n",
    "    def feature(self):\n",
    "        '''call feature building functions on columns'''\n",
    "        for column, func in self.feature_dict.items():\n",
    "            self.df[column] = func(self.df)\n",
    "\n",
    "    def save_mapping(self):\n",
    "        pass\n",
    "\n",
    "    def load_mapping(self):\n",
    "        pass\n",
    "\n",
    "    def get_X(self, sparse=True):\n",
    "        self.vectorizer_ = feature_extraction.DictVectorizer(sparse=sparse)\n",
    "        self.X = self.vectorizer_.fit_transform(self.df[self.x_columns].to_dict(orient='records'))\n",
    "        self.feature_columns_ = self.vectorizer_.vocabulary_\n",
    "        return self\n",
    "\n",
    "    def get_y(self):\n",
    "        self.y = np.array(self.df[self.y_column])\n",
    "        return self.y\n",
    "\n",
    "    def create_model(self, method=None, model_params=None):\n",
    "        if method:\n",
    "            self.method = method\n",
    "        \n",
    "        if model_params:\n",
    "            self.model_params = model_params\n",
    "\n",
    "        if self.method == 'classification':\n",
    "            if model_params:\n",
    "                self.model = xgb.XGBClassifier(**self.model_params)\n",
    "            else:\n",
    "                self.model = xgb.XGBClassifier()\n",
    "            return True\n",
    "        elif self.method == 'regression':\n",
    "            print('Not implemented yet')\n",
    "\n",
    "    def resample(self):\n",
    "        self.sampler = SMOTETomek(n_jobs=-1)\n",
    "        self.X, self.y = self.sampler.fit_sample(self.X, self.y)\n",
    "\n",
    "    def cross_val(self, scoring='accuracy', cv=4, groups=None, seed=42):\n",
    "        cross_vals = model_selection.cross_val_score(self.model, self.X, self.y,\n",
    "                                                     scoring=scoring, cv=cv,\n",
    "                                                     groups=groups, n_jobs=-1)\n",
    "        self.cross_vals = cross_vals\n",
    "        return cross_vals #numpy.mean(cross_vals), numpy.min(cross_vals), numpy.max(cross_vals)\n",
    "    \n",
    "    def train(self, sample_weight=None, eval_metric=None):\n",
    "#         if isinstance(self.model, XGBClassifier):\n",
    "        if sample_weight:\n",
    "            self.sample_weight = sample_weight\n",
    "\n",
    "        if eval_metric:\n",
    "            self.eval_metric = eval_metric\n",
    "        else:\n",
    "            self.eval_metric = 'error'\n",
    "\n",
    "        self.model.fit(self.X, self.y, sample_weight=self.sample_weight, eval_metric=self.eval_metric)\n",
    "        \n",
    "\n",
    "\n",
    "    def pickle(self):\n",
    "        pass\n",
    "\n",
    "    def unpickle(self):\n",
    "        pass\n",
    "\n",
    "    def score(self):\n",
    "        pass\n",
    "\n",
    "    def describe():\n",
    "        from IPython.display import display\n",
    "\n",
    "        if self.df:\n",
    "            self.df.describe()\n",
    "            \n",
    "        if self.model:\n",
    "            print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# production code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_features = len(training_data.columns)-4\n",
    "x_columns = ['feature'+str(i) for i in range(1,num_features)] + ['era_int']\n",
    "y_column = 'target'\n",
    "\n",
    "drop_dict = {}\n",
    "replace_dict = {}\n",
    "convert_dict = {'created': pd.to_datetime,\n",
    "                     'planned_installation_time': pd.to_numeric,\n",
    "                     'status_type': pd.to_numeric}\n",
    "\n",
    "def get_end_of_month(df):\n",
    "    return df['created'].dt.is_month_end\n",
    "\n",
    "def get_era(df):\n",
    "    return df['era'].apply(lambda s: int(s[3:]))\n",
    "\n",
    "feature_dict = {'era_int': get_era}\n",
    "\n",
    "ml = ML(df=training_data, \n",
    "           x_columns=x_columns,\n",
    "           y_column=y_column,\n",
    "           drop_dict=drop_dict,\n",
    "           replace_dict=replace_dict,\n",
    "           convert_dict=convert_dict,\n",
    "           feature_dict=feature_dict)\n",
    "ml.feature()\n",
    "ml.get_X()\n",
    "ml.get_y()\n",
    "# ml.y\n",
    "ml.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create cross_val\n",
    "ml.create_model(method='classification')\n",
    "\n",
    "\n",
    "def cross_val(self, scoring='accuracy', cv=4, group_col=None):\n",
    "    if group_col:\n",
    "        groups = self.df[group_col]\n",
    "    else:\n",
    "        groups = None\n",
    "    cross_vals = model_selection.cross_val_score(self.model, self.X, self.y,\n",
    "                                                 scoring=scoring, cv=cv,\n",
    "                                                 groups=groups, n_jobs=-1)\n",
    "    self.cross_vals = cross_vals\n",
    "    \n",
    "group_col='era'\n",
    "# cross_val(ml, scoring='recall')\n",
    "model_selection.cross_val_score?\n",
    "ml.cross_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train\n",
    "import copy\n",
    "m_ = copy.copy(ml)\n",
    "\n",
    "m_.create_model(method='classification')\n",
    "m_.model.fit(m_.X, m_.y, sample_weight=None, eval_set=None, eval_metric=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.cross_val_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ml.create_model(method='classification')\n",
    "ml.cross_val()\n",
    "# ml.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml.train()\n",
    "y_pred = ml.model.predict()\n",
    "y_prob = ml.model.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ml.create_model(method='classification')\n",
    "model = ml.model\n",
    "df = ml.df.copy()\n",
    "X = ml.X.copy()\n",
    "y = ml.y.copy()\n",
    "# cross val:\n",
    "scoring = 'accuracy'\n",
    "cv = 4\n",
    "groups='era'\n",
    "\n",
    "# cross_vals = model_selection.cross_val_score(model, X, y, scoring=scoring, groups=None, cv=cv, n_jobs=-1)\n",
    "# cross_vals\n",
    "# model_selection.cross_val_score?\n",
    "\n",
    "def train(self, sample_weight=None, eval_metric=None):\n",
    "#         if isinstance(self.model, XGBClassifier):\n",
    "    if sample_weight:\n",
    "        self.sample_weight = sample_weight\n",
    "\n",
    "    if eval_metric:\n",
    "        self.eval_metric = eval_metric\n",
    "    else:\n",
    "        self.eval_metric = 'error'\n",
    "\n",
    "    self.model.fit(self.X, self.y, sample_weight=self.sample_weight, eval_metric=self.eval_metric)\n",
    "    \n",
    "train(ml)\n",
    "# y_pred = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, sample_weight=None, eval_metric=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "xgb.plot_tree(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# unique index\n",
    "df['id'].nunique()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(model.n_columns):\n",
    "    print('feature'+str(i+1))\n",
    "    df.sort_values(by='id').plot(kind='line', x='id', y='feature'+str(i+1))\n",
    "    df.plot(x=df.index, y='feature'+str(i+1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
