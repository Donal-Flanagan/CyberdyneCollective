{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from IPython.display import display\n",
    "from itertools import combinations\n",
    "from copy import deepcopy\n",
    "from pprint import pprint as pp\n",
    "\n",
    "#import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', 11)\n",
    "pd.set_option('display.width', 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_paragraph(text):\n",
    "    \"\"\" \n",
    "    Extract the first paragraph from the text as a string.\n",
    "    It is also removed from the text.\n",
    "    \n",
    "    This will need to be rewritten as a class later so that it\n",
    "    does not have to return the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    first_paragraph = str()\n",
    "        \n",
    "    # iterate through every line of the text\n",
    "    for position, line in enumerate(text):\n",
    "                \n",
    "        # if the line contains only space we stop \n",
    "        if not line:                \n",
    "            text = text[position::]\n",
    "            break\n",
    "\n",
    "        # otherwise we pop out the line and add it to the first paragraph\n",
    "        else:\n",
    "            first_paragraph=first_paragraph+line\n",
    "            \n",
    "    return first_paragraph, text\n",
    "\n",
    "\n",
    "def extract_heading_definitions(text):\n",
    "    important_words = {}\n",
    "        \n",
    "    # iterate through every line of the text\n",
    "    for position, line in enumerate(text):\n",
    "                \n",
    "        # if the line contains only space we stop \n",
    "        if not text[position-2] and not text[position-1]:\n",
    "            # drop the space at the start and the end of the heading\n",
    "            heading = line[1:-1]\n",
    "            important_words[heading] = str()\n",
    "\n",
    "        # otherwise we pop out the line and add it to the first paragraph\n",
    "        elif line:\n",
    "            important_words[heading] += line\n",
    "        \n",
    "    return important_words, text\n",
    "\n",
    "\n",
    "def import_text_and_split_on_spaces(filepath):\n",
    "    file_object = open(filepath, mode='r')\n",
    "    # Import the text as a string\n",
    "    text = file_object.read()\n",
    "    # Split it into a list where each element is a line in string format\n",
    "    text = text.splitlines()\n",
    "    \n",
    "    return text\n",
    "    \n",
    "    \n",
    "    \n",
    "def create_lexicon(filepath):\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    lemmitizer = WordNetLemmatizer()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    lexicon=[]\n",
    "    \n",
    "    all_words = word_tokenize(important_words['Animals'])\n",
    "    \n",
    "    for i in all_words:\n",
    "        i = i.lower()\n",
    "        if i not in stop_words:\n",
    "            if i.isalnum():\n",
    "                lexicon.append(i)\n",
    "    print('lexicon:')\n",
    "    print(lexicon)\n",
    "    \n",
    "    lexicon = [lemmitizer.lemmatize(i) for i in lexicon]\n",
    "    print('\\n')\n",
    "    print('lexicon = [lemmitizer.lemmatize(i) for i in lexicon]:')\n",
    "    print(lexicon)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def extract_important_words(text):\n",
    "    \"\"\"\n",
    "    Given a text in the format of those supplied with the i2x brainteaser, this method: \n",
    "    1. extracts the first paragraph as a general definition of the text's subject, (henceforth referred to as the 'class)\n",
    "    2. takes each following paragraph-title as a feature of the class  \n",
    "    3. takes each paragraph as a definition of its heading\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "\n",
    "    first_paragraph, text = extract_first_paragraph(text)\n",
    "    important_words, text = extract_heading_definitions(text)\n",
    "    # ()\n",
    "    # []\n",
    "    \n",
    "    # Get rid of the references, etc.\n",
    "    for key in important_words.keys():\n",
    "        if key in ['References', 'Notes', 'External links', 'Further reading', 'See also']:\n",
    "            important_words.pop(key, None)\n",
    "\n",
    "    return first_paragraph, important_words\n",
    "\n",
    "def main():\n",
    "    filepath = 'script1.txt'\n",
    "    \n",
    "    text = import_text_and_split_on_spaces(filepath)\n",
    "    \n",
    "    first_paragraph, important_words = extract_important_words(text)\n",
    "    #print()\n",
    "    \n",
    "    print(type(first_paragraph))\n",
    "    print()\n",
    "    \n",
    "    print(important_words['Sweet'])\n",
    "    print(type(important_words['Sweet']))\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
