{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I want to print\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'script1.txt'",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d2b4a8d2eee1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-d2b4a8d2eee1>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"What I want to print\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_lexicon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"script1.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-d2b4a8d2eee1>\u001b[0m in \u001b[0;36mcreate_lexicon\u001b[1;34m(fileIn, n)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mlexicon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\w+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileIn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[1;31m# f is the fileobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# contents is a list of strings where each string is a line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'script1.txt'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_lexicon(fileIn, n):\n",
    "    #nltk.download('wordnet')\n",
    "    #nltk.download(\"stopwords\")\n",
    "    #nltk.download(\"punkt\")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    lemmitizer = WordNetLemmatizer()\n",
    "    lexicon=[]\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    with open(fileIn, 'r') as f:\n",
    "        # f is the fileobject\n",
    "        # contents is a list of strings where each string is a line\n",
    "        # of the text in the fileobject\n",
    "        contents = f.readlines()\n",
    "  \n",
    "        for l in contents[:]:\n",
    "            # l is the line of text, a string\n",
    "            all_words = word_tokenize(l)\n",
    "            # all words is a list of strings, each string a word from the line\n",
    "            \n",
    "            for i in all_words:\n",
    "                i = i.lower()\n",
    "                print(i)\n",
    "                if i not in stop_words:\n",
    "                    print(i)\n",
    "                    if i.isalnum():\n",
    "                        print(i)\n",
    "                        lexicon.append(i)\n",
    "    \n",
    "    lexicon = [lemmitizer.lemmatize(i) for i in lexicon]\n",
    "\n",
    "    #print(lexicon)\n",
    "    w_counts = Counter(lexicon)\n",
    "    \n",
    "    l2 = dict(w_counts)\n",
    "    #l2 = {}\n",
    "    #for w in w_counts:\n",
    "    #    l2[w] = w_counts[w]\n",
    "        \n",
    "    l2 = pd.Series(l2)\n",
    "\n",
    "    l2.sort_values(inplace=True, ascending=False)\n",
    "    \n",
    "    return l2.head(n)\n",
    "\n",
    "def main():\n",
    "    print(\"What I want to print\")\n",
    "    scores = create_lexicon(\"script1.txt\", 20)\n",
    "    print(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              script1  transcript1  transcript2  transcript3\n",
      "food              221        122.0         39.0         68.0\n",
      "cooking            19          NaN          NaN         59.0\n",
      "may                24          6.0         12.0         19.0\n",
      "meat               18         10.0          NaN         19.0\n",
      "vitamin             6          NaN          NaN         18.0\n",
      "fat                10          NaN          NaN         16.0\n",
      "also               16         10.0         12.0         15.0\n",
      "vegetable          13          NaN          NaN         15.0\n",
      "cancer              5          NaN          NaN         14.0\n",
      "many               26          8.0         11.0         13.0\n",
      "raw                13          NaN          NaN         13.0\n",
      "water               7          NaN          NaN         13.0\n",
      "sugar              11          NaN          NaN         12.0\n",
      "used               16          4.0          2.0         12.0\n",
      "ingredient          8          4.0          NaN         11.0\n",
      "heat                7          NaN          NaN         11.0\n",
      "protein             6          NaN          NaN         10.0\n",
      "year                6          6.0          3.0         10.0\n",
      "method             13          NaN          NaN         10.0\n",
      "human              12          NaN          NaN          9.0\n",
      "risk                4          NaN          NaN          9.0\n",
      "often              11         12.0          5.0          8.0\n",
      "form                5          7.0          3.0          7.0\n",
      "world              18         13.0          NaN          7.0\n",
      "use                 8          NaN          NaN          7.0\n",
      "increase            6          NaN          NaN          7.0\n",
      "product            14          6.0          NaN          7.0\n",
      "however             8          NaN          NaN          7.0\n",
      "diet               14          NaN          NaN          6.0\n",
      "oil                 4          NaN          NaN          6.0\n",
      "...               ...          ...          ...          ...\n",
      "packaging           4          NaN          NaN          NaN\n",
      "place               4          NaN          6.0          NaN\n",
      "cold                4          NaN          4.0          NaN\n",
      "china               4          NaN          5.0          NaN\n",
      "reason              4          NaN          NaN          NaN\n",
      "population          4          NaN          NaN          NaN\n",
      "chicken             4          5.0          NaN          NaN\n",
      "starvation          4          NaN          NaN          NaN\n",
      "popular             4          7.0          5.0          NaN\n",
      "slaughter           4          NaN          NaN          NaN\n",
      "promotes            4          NaN          NaN          NaN\n",
      "consumed            4          NaN          NaN          NaN\n",
      "considered          4          3.0          3.0          NaN\n",
      "shop                4         10.0          NaN          NaN\n",
      "soup                4          NaN          NaN          NaN\n",
      "contaminated        4          NaN          NaN          NaN\n",
      "contrast            4          NaN          NaN          NaN\n",
      "sour                4          NaN          NaN          NaN\n",
      "significant         4          NaN          NaN          NaN\n",
      "bitter              4          NaN          NaN          NaN\n",
      "allergen            4          NaN          NaN          NaN\n",
      "major               4          NaN          4.0          NaN\n",
      "longer              4          NaN          NaN          NaN\n",
      "thus                4          NaN          NaN          NaN\n",
      "grill               4          NaN          NaN          NaN\n",
      "lemon               4          NaN          NaN          NaN\n",
      "legal               4          NaN          NaN          NaN\n",
      "group               4          NaN          NaN          NaN\n",
      "growing             4          3.0          5.0          NaN\n",
      "trend               4          NaN          NaN          NaN\n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    script1 = create_lexicon(\"script1.txt\", 200)\n",
    "    transcript1 = create_lexicon(\"transcript_1.txt\", 200)\n",
    "    transcript2 = create_lexicon(\"transcript_2.txt\", 200)\n",
    "    transcript3 = create_lexicon(\"transcript_3.txt\", 200)\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    scores['script1'] = script1\n",
    "    scores['transcript1'] = transcript1\n",
    "    scores['transcript2'] = transcript2\n",
    "    scores['transcript3'] = transcript3\n",
    "    scores.sort_values('transcript3', inplace=True, ascending=False)\n",
    "    print(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}