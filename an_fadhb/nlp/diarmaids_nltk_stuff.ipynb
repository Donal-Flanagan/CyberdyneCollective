{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I want to print\n",
      "food       221\n",
      "animal      31\n",
      "the         30\n",
      "many        26\n",
      "may         24\n",
      "in          24\n",
      "culture     23\n",
      "price       21\n",
      "include     20\n",
      "cooking     19\n",
      "world       18\n",
      "meat        18\n",
      "type        18\n",
      "taste       18\n",
      "plant       18\n",
      "people      16\n",
      "used        16\n",
      "also        16\n",
      "health      16\n",
      "this        16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import numpy\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_lexicon(fileIn, n):\n",
    "    #nltk.download('wordnet')\n",
    "    #nltk.download(\"stopwords\")\n",
    "    #nltk.download(\"punkt\")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    lemmitizer = WordNetLemmatizer()\n",
    "    lexicon=[]\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    with open(fileIn, 'r') as f:\n",
    "        # f is the fileobject\n",
    "        # contents is a list of strings where each string is a line\n",
    "        # of the text in the fileobject\n",
    "        contents = f.readlines()\n",
    "  \n",
    "        for l in contents[:]:\n",
    "            # l is the line of text, a string\n",
    "            all_words = word_tokenize(l)\n",
    "            # all words is a list of strings, each string a word from the line\n",
    "            for i in all_words:\n",
    "                if i not in stop_words:\n",
    "                    if i.isalnum():\n",
    "                        lexicon.append(i.lower())\n",
    "    \n",
    "    lexicon = [lemmitizer.lemmatize(i) for i in lexicon]\n",
    "\n",
    "    #print(lexicon)\n",
    "    w_counts = Counter(lexicon)\n",
    "    \n",
    "    l2 = dict(w_counts)\n",
    "        \n",
    "    l2 = pd.Series(l2)\n",
    "\n",
    "    l2.sort_values(inplace=True, ascending=False)\n",
    "    \n",
    "    return l2.head(n)\n",
    "\n",
    "def main():\n",
    "    print(\"What I want to print\")\n",
    "    scores = create_lexicon(\"script1.txt\", 20)\n",
    "    print(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         script1  transcript1  transcript2  transcript3\n",
      "food         221        122.0         39.0         68.0\n",
      "cooking       19          NaN          NaN         59.0\n",
      "the           30         35.0         25.0         20.0\n",
      "may           24          NaN         12.0         19.0\n",
      "meat          18         10.0          NaN         19.0\n",
      "also          16          NaN         12.0         15.0\n",
      "many          26          NaN         11.0         13.0\n",
      "in            24         27.0         22.0         13.0\n",
      "used          16          NaN          NaN         12.0\n",
      "animal        31          NaN          NaN          NaN\n",
      "culture       23          NaN          NaN          NaN\n",
      "price         21          NaN          NaN          NaN\n",
      "include       20          NaN          NaN          NaN\n",
      "world         18         13.0          NaN          NaN\n",
      "type          18          NaN          NaN          NaN\n",
      "taste         18          NaN          NaN          NaN\n",
      "plant         18          NaN          NaN          NaN\n",
      "people        16          NaN          NaN          NaN\n",
      "health        16          NaN          NaN          NaN\n",
      "this          16          NaN          NaN          NaN\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    script1 = create_lexicon(\"script1.txt\", 20)\n",
    "    transcript1 = create_lexicon(\"transcript_1.txt\", 20)\n",
    "    transcript2 = create_lexicon(\"transcript_2.txt\", 20)\n",
    "    transcript3 = create_lexicon(\"transcript_3.txt\", 20)\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    scores['script1'] = script1\n",
    "    scores['transcript1'] = transcript1\n",
    "    scores['transcript2'] = transcript2\n",
    "    scores['transcript3'] = transcript3\n",
    "    scores.sort_values('transcript3', inplace=True, ascending=False)\n",
    "    print(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
