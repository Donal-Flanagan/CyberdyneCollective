{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What I want to print\n",
      "food       221\n",
      "animal      31\n",
      "many        26\n",
      "may         24\n",
      "culture     23\n",
      "price       21\n",
      "include     20\n",
      "cooking     19\n",
      "taste       18\n",
      "meat        18\n",
      "plant       18\n",
      "world       18\n",
      "type        18\n",
      "health      16\n",
      "used        16\n",
      "also        16\n",
      "people      16\n",
      "country     15\n",
      "product     14\n",
      "diet        14\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "import numpy\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_lexicon(fileIn, n):\n",
    "    #nltk.download('wordnet')\n",
    "    #nltk.download(\"stopwords\")\n",
    "    #nltk.download(\"punkt\")\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    lemmitizer = WordNetLemmatizer()\n",
    "    lexicon=[]\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    with open(fileIn, 'r') as f:\n",
    "        contents = f.readlines()\n",
    "        for l in contents[:]:\n",
    "            all_words = word_tokenize(l)\n",
    "            #all_words = all_words.lower()\n",
    "            for i in all_words:\n",
    "                i = i.lower()\n",
    "                if i not in stop_words:\n",
    "                    if i.isalnum():\n",
    "                        lexicon.append(i)\n",
    "\n",
    "    lexicon = [lemmitizer.lemmatize(i) for i in lexicon]\n",
    "    #print(lexicon)\n",
    "    w_counts = Counter(lexicon)\n",
    "    l2 = {}\n",
    "    for w in w_counts:\n",
    "        l2[w] = w_counts[w]\n",
    "        \n",
    "    l2 = pd.Series(l2)\n",
    "\n",
    "    l2.sort_values(inplace=True, ascending=False)\n",
    "    \n",
    "    return l2.head(n)\n",
    "\n",
    "def main():\n",
    "    print(\"What I want to print\")\n",
    "    scores = create_lexicon(\"script1.txt\", 20)\n",
    "    print(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              script1  transcript1  transcript2  transcript3\n",
      "food              221        122.0         39.0         68.0\n",
      "animal             31          NaN          NaN          5.0\n",
      "many               26          8.0         11.0         13.0\n",
      "may                24          6.0         12.0         19.0\n",
      "culture            23          6.0          NaN          NaN\n",
      "price              21          NaN          3.0          NaN\n",
      "include            20          4.0          NaN          5.0\n",
      "cooking            19          NaN          NaN         59.0\n",
      "taste              18          NaN          NaN          NaN\n",
      "meat               18         10.0          NaN         19.0\n",
      "plant              18          NaN          NaN          2.0\n",
      "world              18         13.0          NaN          7.0\n",
      "type               18          6.0          5.0          4.0\n",
      "health             16          7.0          4.0          6.0\n",
      "used               16          4.0          2.0         12.0\n",
      "also               16         10.0         12.0         15.0\n",
      "people             16          NaN          8.0          2.0\n",
      "country            15         11.0          3.0          NaN\n",
      "product            14          6.0          NaN          7.0\n",
      "diet               14          NaN          NaN          6.0\n",
      "preparation        13          5.0          NaN          5.0\n",
      "vegetable          13          NaN          NaN         15.0\n",
      "raw                13          NaN          NaN         13.0\n",
      "method             13          NaN          NaN         10.0\n",
      "dietary            13          NaN          NaN          NaN\n",
      "known              12          4.0          NaN          5.0\n",
      "market             12          8.0          NaN          NaN\n",
      "production         12          NaN          NaN          NaN\n",
      "oven               12          NaN          NaN          NaN\n",
      "human              12          NaN          NaN          9.0\n",
      "...               ...          ...          ...          ...\n",
      "population          4          NaN          NaN          NaN\n",
      "child               4          NaN          NaN          2.0\n",
      "chicken             4          5.0          NaN          NaN\n",
      "processed           4          NaN          NaN          2.0\n",
      "starvation          4          NaN          NaN          NaN\n",
      "popular             4          7.0          5.0          NaN\n",
      "slaughter           4          NaN          NaN          NaN\n",
      "promotes            4          NaN          NaN          NaN\n",
      "consumed            4          NaN          NaN          NaN\n",
      "considered          4          3.0          3.0          NaN\n",
      "american            4          9.0          3.0          3.0\n",
      "shop                4         10.0          NaN          NaN\n",
      "soup                4          NaN          NaN          NaN\n",
      "contaminated        4          NaN          NaN          NaN\n",
      "contrast            4          NaN          NaN          NaN\n",
      "oil                 4          NaN          NaN          6.0\n",
      "sour                4          NaN          NaN          NaN\n",
      "significant         4          NaN          NaN          NaN\n",
      "bitter              4          NaN          NaN          NaN\n",
      "allergen            4          NaN          NaN          NaN\n",
      "major               4          NaN          4.0          NaN\n",
      "longer              4          NaN          NaN          NaN\n",
      "thus                4          NaN          NaN          NaN\n",
      "grill               4          NaN          NaN          NaN\n",
      "lemon               4          NaN          NaN          NaN\n",
      "legal               4          NaN          NaN          NaN\n",
      "le                  4          3.0          NaN          4.0\n",
      "group               4          NaN          NaN          NaN\n",
      "growing             4          3.0          5.0          NaN\n",
      "trend               4          NaN          NaN          NaN\n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    script1 = create_lexicon(\"script1.txt\", 200)\n",
    "    transcript1 = create_lexicon(\"transcript_1.txt\", 200)\n",
    "    transcript2 = create_lexicon(\"transcript_2.txt\", 200)\n",
    "    transcript3 = create_lexicon(\"transcript_3.txt\", 200)\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    scores['script1'] = script1\n",
    "    scores['transcript1'] = transcript1\n",
    "    scores['transcript2'] = transcript2\n",
    "    scores['transcript3'] = transcript3\n",
    "    #scores = pd.concat([script1,transcript1,transcript2,transcript3])\n",
    "    print(scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
