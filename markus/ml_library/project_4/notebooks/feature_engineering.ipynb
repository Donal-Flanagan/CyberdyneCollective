{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from utils import set_project_dir\n",
    "set_project_dir('project_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, model_selection, metrics\n",
    "import missingno as miss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/in/train.csv')\n",
    "test = pd.read_csv('data/in/test.csv')\n",
    "\n",
    "# column to mark outliers\n",
    "train['outlier'] = False\n",
    "\n",
    "x_columns = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering\n",
    "## general information\n",
    "### numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation between (numerical) features and target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()['SalePrice'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select_dtypes('object').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one-way ANOVA to test whether the mean of different groups are significant\n",
    "- or how groups of the IV affect the DV\n",
    "- have to check for all individual groups as well, see here: http://hamelg.blogspot.de/2015/11/python-for-data-analysis-part-16_23.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = train.select_dtypes('object').columns[17]\n",
    "sns.boxplot(train[column], y)\n",
    "# print(train[column].value_counts())\n",
    "sp.stats.f_oneway(*[group for _, group in train.groupby(column)['SalePrice'].groups.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target variable: SalePrice\n",
    "- the target variable has a skewed distribution (skewness of normal distribution is 0), so it is better to transform it so it more resembles a normal dist.\n",
    "- also the kurtosis (measure of fat tail distributions, or likelihood of encountering extreme values) is higher than normal distribution (definition here is excess kurtosis = kurtosis - 3 = 0 for normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'SalePrice'\n",
    "y = train[y_column]\n",
    "\n",
    "sns.distplot(y)\n",
    "print(y.skew(), y.kurtosis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the logarithm to more resemble a normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = 'logSalePrice'\n",
    "train[y_column] = np.log(y)\n",
    "y = train[y_column] # y only points to the pandas series. so in principle, we can still manipulate the underlying column, and use y as shorthand to refer to it.\n",
    "sns.distplot(y)\n",
    "print(y.skew(), y.kurtosis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if outcome is approximately normal. distribution shows fat tail deviations on lower end:\n",
    "\n",
    "https://www.itl.nist.gov/div898/handbook/eda/section3/probplot.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sp.stats.probplot(y, dist='norm', plot=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature: OverallQual\n",
    "- ranked categorical feature, use spearman correlation to check for monotony instead of linearity (pearson)\n",
    "- fit linear: order=1\n",
    "- use x_jitter to add noise to the categorical data, more pleasant for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['OverallQual']\n",
    "sns.jointplot(x, y, kind='reg', stat_func=sp.stats.spearmanr, order=1, x_jitter=0.4)\n",
    "x_columns.append('OverallQual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature: GrLivArea\n",
    "- there are some outliers, which have to be thrown out\n",
    "- also the relationship is not really linear, might rather follow $y \\sim log(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['GrLivArea']\n",
    "sns.jointplot(x, y, kind='reg', logx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mark outliers and transform to logarithmic scale. output looks kind of better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(y<12.5)&(x>4000), 'outlier'] = True\n",
    "train['logGrLivArea'] = np.log(x)\n",
    "x = train['logGrLivArea']\n",
    "sns.jointplot(x, y, kind='reg', order=1)\n",
    "x_columns.append('logGrLivArea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature: GarageCars\n",
    "- if one feature is categorical, it might make sense to plot the mean/median instead of all values. then we can better see if a linear relationship holds\n",
    "- apparently, the data follows a linear form up until 3. after that, it doesn't hold anymore. we can encode that as a new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['GarageCars']\n",
    "sns.jointplot(x, y, kind='reg', order=1, x_estimator=np.median)\n",
    "train['4GarageCars'] = x==4\n",
    "x_columns += ['GarageCars', '4GarageCars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also use a boxplot to show the progression of the median of the feature vs target. here, we can also see whether outliers are present. however, no regression line extract the linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature: GarageArea\n",
    "- garage area = 0 indicates no garage, might be worth a new feature. But already follows a linear relationship, so it won't add much information.\n",
    "- also, there are some outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['GarageArea']\n",
    "sns.jointplot(x, y, kind='reg')\n",
    "sns.jointplot(x, y, kind='reg', x_bins=np.arange(0,1000,100), x_estimator=np.median)\n",
    "x_columns.append(x.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mark outliers and create new feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(x>1200) & (y<12.5), 'outlier'] = True\n",
    "train['noGarage'] = (x==0)\n",
    "sns.boxplot(train['noGarage'], y)\n",
    "x_columns.append('noGarage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature: TotalBsmtSF\n",
    "same story, filter out outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['TotalBsmtSF']\n",
    "sns.jointplot(x, y, kind='reg')\n",
    "train.loc[x>4000, 'outlier'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature: Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['Neighborhood']\n",
    "sns.boxplot(x, y)\n",
    "temp = pd.get_dummies(x, drop_first=False)\n",
    "train = train.merge(temp, how='left', left_index=True, right_index=True, copy=False) #ATTENTION: creates a copy of the df, so previous references x,y are pointing to the old df\n",
    "x_columns += list(temp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature: MSZoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train['MSZoning']\n",
    "sns.boxplot(x, y)\n",
    "temp = pd.get_dummies(x, drop_first=False)\n",
    "train = train.merge(temp, how='left', left_index=True, right_index=True, copy=False)\n",
    "x_columns += list(temp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handling NaN\n",
    "https://medium.com/ibm-data-science-experience/missing-data-conundrum-exploration-and-imputation-techniques-9f40abe0fd87\n",
    "\n",
    "- we definitely see some patterns for missing data. so we might just filter them out?\n",
    "- also, some features aren't filled at all, so we either throw them away or encode them as new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = train.columns[train.isnull().any()]\n",
    "miss.matrix(train[nan_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, we can see, whether one feature missing correlates with another feature missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss.heatmap(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict\n",
    "- $R^2$ gives the variance explained by prediction\n",
    "- apparently, it makes sense to leave out GrLivArea, since we already have the logarithmic feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_columns)\n",
    "X = train[x_columns]\n",
    "# X = train[['OverallQual', 'logGrLivArea', 'GarageCars', '4GarageCars', 'GarageArea', 'noGarage']]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, # X.loc[~train['outlier']], y.loc[~train['outlier']],\n",
    "                                                                    test_size=0.33, random_state=42)\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('R^2 =', clf.score(X_test, y_test))\n",
    "print('RMS =', metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try out Ridge regularization, which reduces the regression coefficients of less important features (doesn't make much of a difference here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(alpha=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('R^2 =', clf.score(X_test, y_test))\n",
    "print('RMS =', metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the predicted target vs real target. we can see, that there are some values which are far off from being predicted accurately.\n",
    "also the predictions should follow on average a straight line through the origin, $y_{pred}(y) = y$, which is not the case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.regplot(y_test, y_pred, fit_reg=True)\n",
    "plt.plot([10,15], [10,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cannot get regression line parameters directly, so we have to dig through the matplotlib metadata. then we get the current linear relationship between $y_{pred}$ and $y$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(plot.get_children())\n",
    "regression = plot.get_lines()[0]\n",
    "reg_x = regression.get_xdata()\n",
    "reg_y = regression.get_ydata()\n",
    "b = (reg_y[-1] - reg_y[0])/(reg_x[-1] - reg_x[0])\n",
    "a = reg_y[0] - b * reg_x[0]\n",
    "print('y = {a} + {b} x'.format(a=a, b=b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## super stupid brute force model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[[f for f in train.columns\n",
    "           if f not in ['LotFrontage', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature', 'SalePrice', 'Id']]]\n",
    "X = X.join(pd.get_dummies(X.select_dtypes('object')))\n",
    "X = X[[f for f in X.columns if f not in X.select_dtypes('object').columns]]\n",
    "y = train['logSalePrice']\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "# X.dropna(inplace=True)\n",
    "# y = y.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, # X.loc[~train['outlier']], y.loc[~train['outlier']],\n",
    "                                                                    test_size=0.33)\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('R^2 =', clf.score(X_test, y_test))\n",
    "print('RMS =', metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.regplot(y_test, y_pred, fit_reg=True)\n",
    "plt.plot([10,15], [10,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[[f for f in test.columns\n",
    "           if f not in ['LotFrontage', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature', 'SalePrice', 'Id']]]\n",
    "X_test = X_test.join(pd.get_dummies(X_test.select_dtypes('object')))\n",
    "X_test = X_test[[f for f in X_test.columns if f not in X_test.select_dtypes('object').columns]]\n",
    "X_test.fillna(X_test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "629px",
    "left": "0px",
    "right": "1228px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
