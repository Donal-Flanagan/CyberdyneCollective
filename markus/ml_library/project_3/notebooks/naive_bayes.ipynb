{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import scipy as sp\n",
    "# from sklearn import preprocessing, feature_extraction, feature_selection, model_selection, metrics\n",
    "# import xgboost as xgb\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import set_project_dir\n",
    "set_project_dir('project_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/in/train.csv')\n",
    "test = pd.read_csv('data/in/test.csv')\n",
    "y_column = 'Survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bayesian statistics\n",
    "posterior probability:\n",
    "\\begin{equation}P(y|x_i) = \\frac{P(x_i|y)P(y)}{P(x_i)}\\end{equation}\n",
    "- class $y$, features $x_i$\n",
    "- $P(y)$ class prior probability\n",
    "- $P(x_i)$ predictor prior probability\n",
    "- $P(x_i|y)$ likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical features\n",
    "### basics\n",
    "example:\n",
    "\n",
    "- $x_i$ = Pclass\n",
    "- frequency table with $n_{kl}$ for $y=k$ and $x_i=l$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train['Pclass'], train[y_column], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $N = \\sum_{kl} n_{kl}$\n",
    "- $N_k = \\sum_l n_{kl}$\n",
    "- $N_l = \\sum_k n_{kl}$\n",
    "- likelihood $P(x_i=k | y=l) = n_{kl}/N_l$\n",
    "- class prior $P(y=l) = N_l/N$\n",
    "- predictor prior $P(x_i=k) = N_k/N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab = pd.crosstab(train['Pclass'], train[y_column], normalize='columns', margins=True)\n",
    "predictor_prior = crosstab['All']\n",
    "likelihood = crosstab[[0, 1]]\n",
    "\n",
    "crosstab = pd.crosstab(train['Pclass'], train[y_column], normalize='index', margins=True)\n",
    "class_prior = crosstab.loc['All']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unnormalized posterior: $\\tilde p_{kl} := P(x_i|y) P(y)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = likelihood * class_prior\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- either use predictor prior $P(x_i)$ for normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = p / pd.DataFrame({col: predictor_prior for col in p.columns})\n",
    "posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- or normalize by hand: $\\tilde p_{kl} / \\sum_l \\tilde p_{kl}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = p.sum(axis=1)\n",
    "posterior = p / pd.DataFrame({col: norm for col in p.columns})\n",
    "posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = train[['Pclass', 'Survived']]\n",
    "predict = predict.join(posterior, on='Pclass')\n",
    "predict['Survived_pred'] = predict[[0,1]].idxmax(axis=1)\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts = pd.crosstab(predict['Survived'], predict['Survived_pred'], margins='all')\n",
    "pred_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (pred_counts.loc[1,1] + pred_counts.loc[0,0]) / pred_counts.loc['All', 'All']\n",
    "precision = pred_counts.loc[1,1] / pred_counts.loc['All',1]\n",
    "recall = pred_counts.loc[1,1] / pred_counts.loc[1,'All']\n",
    "accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = ['Pclass', 'Embarked']\n",
    "predictor_prior = dict()\n",
    "likelihood = dict()\n",
    "class_prior = dict()\n",
    "\n",
    "for x_i in x_columns:\n",
    "    crosstab = pd.crosstab(train[x_i], train[y_column], normalize='columns', margins=True)\n",
    "    predictor_prior[x_i] = crosstab['All']\n",
    "    likelihood[x_i] = crosstab[[0, 1]]\n",
    "\n",
    "# class prior does not depend on features, so is the same for all\n",
    "crosstab = pd.crosstab(train[x_columns[0]], train[y_column], normalize='index', margins=True)\n",
    "class_prior = crosstab.loc['All']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\tilde p_{kl} = \\left[\\prod_i P(x_i|y) \\right] P(y)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_crossjoin(df1, df2, **kwargs):\n",
    "    df1['_tmpkey'] = 1\n",
    "    df2['_tmpkey'] = 1\n",
    "\n",
    "    res = pd.merge(df1, df2, on='_tmpkey', suffixes=('', '_2'), **kwargs).drop('_tmpkey', axis=1)\n",
    "    res.index = pd.MultiIndex.from_product((df1.index, df2.index))\n",
    "\n",
    "    df1.drop('_tmpkey', axis=1, inplace=True)\n",
    "    df2.drop('_tmpkey', axis=1, inplace=True)\n",
    "\n",
    "    return res\n",
    "\n",
    "temp = df_crossjoin(likelihood[x_columns[0]], likelihood[x_columns[1]])\n",
    "temp['0'] = temp['0'] * temp['0_2']\n",
    "temp['1'] = temp['1'] * temp['1_2']\n",
    "p = temp.drop(['0_2', '1_2'], axis=1).rename(lambda x: int(x), axis=1) * class_prior\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize each row by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = p.sum(axis=1)\n",
    "posterior = p / pd.DataFrame({col: norm for col in p.columns})\n",
    "posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization with predictor priors does not work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_crossjoin(pd.DataFrame(predictor_prior[x_columns[0]]), pd.DataFrame(predictor_prior[x_columns[1]]))\n",
    "temp['All'] = temp['All'] * temp['All_2']\n",
    "temp['All_2'] = temp['All']\n",
    "temp.rename({'All': 0, 'All_2': 1}, axis=1, inplace=True)\n",
    "p / temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = train[x_columns + [y_column]]\n",
    "predict = predict.join(posterior, on=x_columns)\n",
    "predict['Survived_pred'] = predict[[0,1]].idxmax(axis=1)\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts = pd.crosstab(predict['Survived'], predict['Survived_pred'], margins='all')\n",
    "pred_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (pred_counts.loc[1,1] + pred_counts.loc[0,0]) / pred_counts.loc['All', 'All']\n",
    "precision = pred_counts.loc[1,1] / pred_counts.loc['All',1]\n",
    "recall = pred_counts.loc[1,1] / pred_counts.loc[1,'All']\n",
    "accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continuous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basics\n",
    "two (three) possibilities:\n",
    "1. use a normal distribution\n",
    "    - best, when $P(x_i|y)$ is normal distributed\n",
    "2. discretize continuous features\n",
    "    - if distribution not normal\n",
    "3. use a kernel density estimator\n",
    "    - best, but introduces KDE bandwidth as new hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gaussian\n",
    "apparently, the likelihoods are not normal distributed. But we continue anyways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column = 'Age'\n",
    "train[train[y_column]==0].hist(x_column)\n",
    "train[train[y_column]==1].hist(x_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compute mean and std of $x_i$ for each class outcome $y=l$\n",
    "(clean outliers before, because mean is very sensitive to them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.DataFrame(columns=[0,1], index=['mean', 'std'])\n",
    "for col in params.columns:\n",
    "    temp = train.loc[train[y_column]==col,x_column]\n",
    "    params[col] = [temp.mean(), temp.std()]\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict\n",
    "- likelihood $P(x_i|y=l) ~ N(\\mu^i_l, \\sigma^i_l)$ is continuous and gaussian distributed\n",
    "- compute $P(x_i=k|y=l)$ for every observation k, finally multiply by class prior\n",
    "- normalize rows individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(x, mean, std):\n",
    "    return 1/(np.sqrt(2*np.pi)*std) * np.exp(-(x-mean)**2/(2*std**2))\n",
    "\n",
    "def predict(series, params, class_prior):\n",
    "    pred = pd.DataFrame(1, columns=params.columns, index=series.index)\n",
    "    for col in params.columns:\n",
    "        pred[col] = normal(series, *list(params[col]))\n",
    "    pred *= class_prior\n",
    "    \n",
    "    norm = pred.sum(axis=1)\n",
    "    return pred / pd.DataFrame({col: norm for col in pred.columns})\n",
    "\n",
    "crosstab = pd.crosstab(train[x_column], train[y_column], normalize='index', margins=True)\n",
    "class_prior = crosstab.loc['All']\n",
    "predict = predict(train[x_column], params, class_prior)\n",
    "predict[y_column] = train[y_column]\n",
    "predict['Survived_pred'] = predict[[0,1]].idxmax(axis=1)\n",
    "predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_counts = pd.crosstab(predict['Survived'], predict['Survived_pred'], margins='all')\n",
    "pred_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (pred_counts.loc[1,1] + pred_counts.loc[0,0]) / pred_counts.loc['All', 'All']\n",
    "precision = pred_counts.loc[1,1] / pred_counts.loc['All',1]\n",
    "recall = pred_counts.loc[1,1] / pred_counts.loc[1,'All']\n",
    "accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# naive bayes with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we first have to transform our dataset into a contingency table (which is: counts for each feature outcome given the class outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transf = train[['Pclass', 'Embarked', 'Survived']]\n",
    "train_transf.set_index(['Pclass', 'Embarked'], inplace=True)\n",
    "pd.crosstab(train_transf.index, train_transf['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(train[['Survived', 'Pclass', 'Embarked']], columns=['Pclass', 'Embarked']).groupby('Survived').sum()\n",
    "pd.DataFrame(index=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = ['Pclass']\n",
    "y_column = 'Survived'\n",
    "\n",
    "train_transf = train[x_columns+[y_column]].copy().dropna()\n",
    "train_transf['Pclass'] = train_transf['Pclass'] - 1\n",
    "le = LabelEncoder()\n",
    "if 'Embarked' in x_columns:\n",
    "    le.fit(list(train_transf['Embarked'].unique()))\n",
    "    train_transf['Embarked'] = le.transform(train_transf['Embarked'].fillna('nan'))\n",
    "\n",
    "model = MultinomialNB(alpha=0, fit_prior=True, class_prior=np.array(class_prior))\n",
    "# model.fit(np.asarray(train_transf[x_columns]), np.asarray(train_transf[y_column]))\n",
    "model.partial_fit(np.asarray(train_transf[x_columns]), np.asarray(train_transf[y_column]),\n",
    "                  classes=np.asarray(train_transf[y_column].unique()))\n",
    "model.predict_proba(train_transf[x_columns])\n",
    "\n",
    "# model.score(np.asarray(train_transf[x_columns]), np.asarray(train_transf[y_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = ['Age']\n",
    "train_transf = train[x_columns+[y_column]].copy().dropna()\n",
    "temp = train_transf[x_columns]\n",
    "# normalize feature columns (apparently, this is done in GaussianNB already)\n",
    "# train_transf[x_columns] = (train_transf[x_columns] - temp.mean())/temp.std()\n",
    "model = GaussianNB()\n",
    "model.fit(train_transf[x_columns], train_transf[y_column])\n",
    "model.predict_proba(train_transf[x_columns])[:10]\n",
    "# model.score(train_transf[x_columns], train_transf[y_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## minimal example sklearn categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "train = pd.read_csv('data/in/train.csv')\n",
    "\n",
    "X_test = np.asarray(pd.get_dummies(train['Pclass']))\n",
    "# y_test = np.asarray(train['Survived'])\n",
    "\n",
    "X = np.array(pd.crosstab(train[y_column], train['Pclass']))\n",
    "y = np.array([0, 1])\n",
    "\n",
    "clf = MultinomialNB(alpha=0.0000000001, fit_prior=True, class_prior=np.array(class_prior))\n",
    "clf.fit(X, y)\n",
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "629px",
    "left": "0px",
    "right": "1228px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
