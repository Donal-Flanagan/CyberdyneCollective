{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Classification Example with TensorFlow\n",
    "\n",
    "This notebook is a companion of [A Visual and Interactive Guide to the Basics of Neural Networks](https://jalammar.github.io/visual-interactive-guide-basics-neural-networks/).\n",
    "\n",
    "This is an example of how to do classification on a simple dataset in TensorFlow. Basically, we're building a model to help a friend choose a house to buy. She has given us the table below of houses and whether she likes them or not. We're to build a model that takes a house area and number of bathrooms as input, and outputs a prediction of whether she would like the house or not.\n",
    "\n",
    "| Area (sq ft) (x1) | Bathrooms (x2) | Label (y) |\n",
    " | --- | --- | --- |\n",
    " | 2,104 |  3 | Good |\n",
    " | 1,600 |  3 | Good |\n",
    " | 2,400 |  3 | Good |\n",
    " | 1,416 | \t2 | Bad |\n",
    " | 3,000 | \t4 | Bad |\n",
    " | 1,985 | \t4 | Good |\n",
    " | 1,534 | \t3 | Bad |\n",
    " | 1,427 | \t3 | Good |\n",
    " | 1,380 | \t3 | Good |\n",
    " | 1,494 | \t3 | Good |\n",
    " \n",
    " \n",
    " \n",
    " We'll start by loading our favorite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline               \n",
    "import pandas as pd              # A beautiful library to help us work with data as tables\n",
    "import numpy as np               # So we can use number matrices. Both pandas and TensorFlow need it. \n",
    "import matplotlib.pyplot as plt  # Visualize the things\n",
    "import tensorflow as tf          # Fire from the gods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then load the house data CSV. Pandas is an incredible library that gives us great flexibility in dealing with table-like data. We load tables (or csv files, or excel sheets) into a \"data frame\", and process it however we like. You can think of it as a programatic way to do a lot of the things you previously did with Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data.csv\") # Let's have Pandas load our dataset as a dataframe\n",
    "dataframe = dataframe.drop([\"index\", \"price\", \"sq_price\"], axis=1) # Remove columns we don't care about\n",
    "dataframe = dataframe[0:10] # We'll only use the first 10 rows of the dataset in this example\n",
    "dataframe # Let's have the notebook show us how the dataframe looks now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe now only has the features. Let's introduce the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[:, (\"y1\")] = [1, 1, 1, 0, 0, 1, 0, 1, 1, 1] # This is our friend's list of which houses she liked\n",
    "                                                          # 1 = good, 0 = bad\n",
    "dataframe.loc[:, (\"y2\")] = dataframe[\"y1\"] == 0           # y2 is the negation of y1\n",
    "dataframe.loc[:, (\"y2\")] = dataframe[\"y2\"].astype(int)    # Turn TRUE/FALSE values into 1/0\n",
    "# y2 means we don't like a house\n",
    "# (Yes, it's redundant. But learning to do it this way opens the door to Multiclass classification)\n",
    "dataframe # How is our dataframe looking now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all our data in the dataframe, we'll need to shape it in matrices to feed it to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputX = dataframe.loc[:, ['area', 'bathrooms']].as_matrix()\n",
    "inputY = dataframe.loc[:, [\"y1\", \"y2\"]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now our input matrix looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our labels matrix looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare some parameters for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.000001\n",
    "training_epochs = 2000\n",
    "display_step = 50\n",
    "n_samples = inputY.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to define the TensorFlow operations. Notice that this is a declaration step where we tell TensorFlow how the prediction is calculated. If we execute it, no calculation would be made. It would just acknowledge that it now knows how to do the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 2])   # Okay TensorFlow, we'll feed you an array of examples. Each example will\n",
    "                                            # be an array of two float values (area, and number of bathrooms).\n",
    "                                            # \"None\" means we can feed you any number of examples\n",
    "                                            # Notice we haven't fed it the values yet\n",
    "            \n",
    "W = tf.Variable(tf.zeros([2, 2]))           # Maintain a 2 x 2 float matrix for the weights that we'll keep updating \n",
    "                                            # through the training process (make them all zero to begin with)\n",
    "    \n",
    "b = tf.Variable(tf.zeros([2]))              # Also maintain two bias values\n",
    "\n",
    "y_values = tf.add(tf.matmul(x, W), b)       # The first step in calculating the prediction would be to multiply\n",
    "                                            # the inputs matrix by the weights matrix then add the biases\n",
    "    \n",
    "y = tf.nn.softmax(y_values)                 # Then we use softmax as an \"activation function\" that translates the\n",
    "                                            # numbers outputted by the previous layer into probability form\n",
    "    \n",
    "y_ = tf.placeholder(tf.float32, [None,2])   # For training purposes, we'll also feed you a matrix of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify our cost function and use Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cost function: Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(y_ - y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variabls and tensorflow session\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Drum roll*\n",
    "\n",
    "And now for the actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(training_epochs):  \n",
    "    sess.run(optimizer, feed_dict={x: inputX, y_: inputY}) # Take a gradient descent step using our inputs and labels\n",
    "\n",
    "    # That's all! The rest of the cell just outputs debug messages. \n",
    "    # Display logs per epoch step\n",
    "    if (i) % display_step == 0:\n",
    "        cc = sess.run(cost, feed_dict={x: inputX, y_:inputY})\n",
    "        print \"Training step:\", '%04d' % (i), \"cost=\", \"{:.9f}\".format(cc) #, \\\"W=\", sess.run(W), \"b=\", sess.run(b)\n",
    "\n",
    "print \"Optimization Finished!\"\n",
    "training_cost = sess.run(cost, feed_dict={x: inputX, y_: inputY})\n",
    "print \"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training is done. TensorFlow is now holding on to our trained model (Which is basically just the defined operations, plus the variables W and b that resulted from the training process).\n",
    "\n",
    "Is a cost value of 0.109537 good or bad? I have no idea. At least it's better than the first cost value of 0.114958666. Let's use the model on our dataset to see how it does, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(y, feed_dict={x: inputX })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So It's guessing they're all good houses. That makes it get 7/10 correct. Not terribly impressive. A model with a hidden layer should do better, I guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Btw, this is how I calculated the softmax values in the post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.nn.softmax([1., 2.]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
