{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Polynomial Chaos: A technique for modeling uncertainty\n",
    "\n",
    "### Emily Gorcenski\n",
    "### @EmilyGorcenski\n",
    "\n",
    "[Download talk at emilygorcenski.com/pydata-berlin.ipynb](http://emilygorcenski.com/pydata-berlin.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Content Notes\n",
    "\n",
    "- Will be talking about differential equations and functional analysis with no setup.\n",
    "- No QA, but feel free to chat/ask questions 1:1 or in small group during hallway track.\n",
    "- Warning: I write python like a functional programmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial Chaos is a way of representing random variables/random processes in terms of orthogonal polynomials\n",
    "\n",
    "- Can be thought of a special case of Kosambi-Karhunen-Lo√®ve\n",
    "- Can equivalently be thought of as PCA over an orthogonal vector space of polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### KKL Transform\n",
    "$X_t = \\sum_{i=0}^\\infty Z_i e_i(t)$\n",
    "\n",
    "#### PCA\n",
    "$X = \\sum_{i=0}^N \\langle \\phi_i, X \\rangle \\phi_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Polynomial Chaos\n",
    "$X = \\sum_{i=0}^\\infty X_i \\Phi_i(\\zeta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Polynomial Chaos lets us represent annoying uncertainty in terms that we can control\n",
    "\n",
    "- Allows for acceleration of Monte Carlo simulation\n",
    "  - Shifts the burden from computing stochastic solutions to computing deterministic parameters\n",
    "- Allows us to handle distributions without convenient forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Cameron-Martin theorem guarantees that the Polynomial Chaos representation converges to an $L^2$ functional in the $L^2$ sense: we can therefore use it to represent a random process belonging to any distribution with a finite second moment (aka finite variance). (target var needs finite second moment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simpler Terms: We can represent random variables of arbitrary distributions using a Polynomial Chaos expansion about a random variable **of our choice**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There exists a natural relationship between orthogonal polynomials and probability distributions.\n",
    "\n",
    "Hermite Polynomials:\n",
    "\n",
    "$$ \\langle H_i(\\zeta)\\, H_j(\\zeta) \\rangle  = \\int_{-\\infty}^\\infty H_i(\\zeta) H_j(\\zeta) \\color{red}{e^{-\\frac{\\zeta^2}{2}}}\\, d\\zeta = \\color{red}{\\sqrt{2\\pi}} i! \\delta_{ij}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This looks very Gaussian! We can then use the Polynomial Chaos representation to write **any** finite-variance random variable $k$ as a series of Hermite polynomials about a Gaussian r.v.\n",
    "\n",
    "$$k = \\sum_{i=0}^\\infty k_i H_i(\\zeta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The $k_i$ are deterministic coefficients. We use the Galerkin projection to compute them: (looks similar to FT)\n",
    "\n",
    "$$k_i = \\frac{\\langle k H_i(\\zeta) \\rangle}{\\langle H_i^2(\\zeta) \\rangle} = \\frac{1}{\\langle H_i^2 \\rangle} \\int_{-\\infty}^\\infty k H_i(\\zeta) e^{-\\frac{\\zeta^2}{2}}\\, d\\zeta.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use the fact that $k$ and $\\zeta$ are fully dependent and perform an inverse sample transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using the CDF of both random variables, transform them to the same **uniform** random variable supported on $[0,1]$.\n",
    "\n",
    "$$u = G(\\zeta) = F(k).$$\n",
    "\n",
    "$$k = F^{-1}(u) \\stackrel{\\small{\\textrm{def}}}{=} h(u),$$\n",
    "$$\\zeta = G^{-1}(u) \\stackrel{\\small{\\textrm{def}}}{=} l(u).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using this transform, the integral is transformed:\n",
    "\n",
    "$$\\int_{-\\infty}^\\infty k H_i(\\zeta) e^{-\\frac{\\zeta^2}{2}}\\, d\\zeta \\Longrightarrow \\int_0^1 h(u) H_i(l(u))\\, du$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can then compute the coefficients $k_i$ with a fairly basic integral:\n",
    "\n",
    "$$k_i = \\frac{1}{\\langle H_i^2 \\rangle}\\int_0^1 h(u) H_i(l(u))\\, du.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What about that inner product? Three options:\n",
    "\n",
    "- Use the closed form representation from the orthogonality condition: $ \\langle H_i^2(\\zeta) \\rangle = \\sqrt{2\\pi} i!$;\n",
    "- Choose a scaling of $\\zeta$ such that the orthogonality condition is just the Kronecker delta;\n",
    "- Just compute the integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Option 2 is best, but tedious. So let's go with option three using Gauss-Hermite quadrature.\n",
    "\n",
    "$$\\int_{-\\infty}^\\infty f(x) e^{-\\frac{x^2}{2}}\\, dx \\approx \\sum_{i=0}^N w_i f(x_i).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ok less words more code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reminder: we want to compute $k_i$ so that we can assemble a random variable of an arbitrary distribution using Gaussian random variables with zero mean and standard deviation $1$ (aka standard normal):\n",
    "\n",
    "$$k = \\sum_{i=0}^\\infty k_i H_i(\\zeta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial.hermite_e as H\n",
    "from scipy.stats import norm\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def Herm(n):\n",
    "    coeffs = [0] * (n+1)\n",
    "    coeffs[n] = 1\n",
    "    return coeffs\n",
    "\n",
    "def inner_product(h1, h2):\n",
    "    return lambda x: H.hermeval(x, H.hermemul(h1, h2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def trapezoid_int(f, a, b, n=100):\n",
    "    P = [a + i * (b - a) / n for i in range(0, n + 1)]\n",
    "    F = [1 / 2 * np.abs(P[i+1] - P[i]) * (f(P[i+1]) + f(P[i])) for i in range(0, len(P)-1)]\n",
    "    return sum(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def unif_icdf(params):\n",
    "    a = params[0]\n",
    "    b = params[1]\n",
    "    return lambda u : u * (b - a) + a\n",
    "\n",
    "def expo_icdf(params):\n",
    "    return lambda u : -np.log(1-u)\n",
    "\n",
    "def norm_icdf(params):\n",
    "    return lambda u : norm.ppf(u, loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def approximate_rv_coeffs(P, h):\n",
    "    # initialize lists for output to make syntax more canonical with the math\n",
    "    ki = [0] * P\n",
    "    \n",
    "    # Set up Gauss-Hermite quadrature\n",
    "    m = P**2\n",
    "    x, w = H.hermegauss(m)\n",
    "    \n",
    "    # Compute the coefficients, and also build out k in the same pass\n",
    "    for i in range(0, P):\n",
    "        # compute the inner product with Gauss-Hermite quadrature\n",
    "        ip = sum([inner_product(Herm(i), Herm(i))(x[idx]) * w[idx] for idx in range(m)])\n",
    "        # compute the integral\n",
    "        integrand = lambda u : h(u) *  H.hermeval(norm.ppf(u, loc=0, scale=1), Herm(i))\n",
    "        ki[i] = np.sqrt(2*np.pi) / ip * trapezoid_int(integrand, 0.001, 1-0.001, 1000)\n",
    "    return ki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# generate random variable from coefficients k_i\n",
    "def generate_rv(ki, S):\n",
    "    # build out k termwise\n",
    "    k = [0] * len(S)\n",
    "    for i in range(len(ki)):\n",
    "        k = np.add(k, ki[i] * H.hermeval(S, Herm(i)))\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a bunch of Gaussian random variables to use\n",
    "N = 5000\n",
    "S = np.random.normal(loc=0, scale=1, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "h = unif_icdf([0,1])\n",
    "ki_uniform = approximate_rv_coeffs(13, h)\n",
    "k = generate_rv(ki_uniform, S)\n",
    "out = plt.hist(k, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# k_0 is always mean\n",
    "# k_1 is always standard deviation\n",
    "# k_2 is kurtosis ...\n",
    "ki_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "h = expo_icdf([])\n",
    "ki_expo = approximate_rv_coeffs(13, h)\n",
    "k_expo = generate_rv(ki_expo, S)\n",
    "out = plt.hist(k_expo, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Must we use Gaussian random variables?\n",
    "\n",
    "No! The Wiener-Askey scheme is rad.\n",
    "\n",
    "|             | Distribution      | Family     | Support                |\n",
    "|:------------|:------------------|:-----------|------------------------|\n",
    "| Continuous  | Gaussian          | Hermite    | $(-\\infty, \\infty)$    |\n",
    "|             | Uniform           | Legendre   | $[a,b]$                |\n",
    "|             | Gamma             | Laguerre   | $[0,\\infty)$           |\n",
    "|             | Beta              | Jacobi     | $[a,b]$                |\n",
    "| Discrete    | Poisson           | Charlier   | $\\{0,1,\\ldots\\}$       |\n",
    "|             | Negative Binomial | Miexner    | $\\{0,1,\\ldots\\}$       |\n",
    "|             | Binomial          | Krawtchouk | $\\{0,1,\\ldots\\, N\\}$   |\n",
    "|             | Hypergeometric    | Hahn       | $\\{0,1,\\ldots\\, N\\}$   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Wiener-Askey scheme](wa.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\\langle \\Phi_i(\\zeta) \\Phi_j(\\zeta) \\rangle = \\int_S \\Phi_i(\\zeta) \\Phi_j(\\zeta) \\color{red}{w(\\zeta)\\, d\\zeta}$$\n",
    "\n",
    "$$w(\\zeta)\\, d\\zeta = \\frac{d\\mu}{d\\zeta}d\\zeta$$\n",
    "\n",
    "Generalize to\n",
    "\n",
    "$$\\langle \\Phi_i(\\zeta) \\Phi_j(\\zeta) \\rangle = \\int_S \\Phi_i(\\zeta) \\Phi_j(\\zeta) d\\mu \\Longrightarrow \\sum_{n\\in S} \\Phi_i\\left(\\zeta_n\\right)\\Phi_j\\left(\\zeta_n\\right)w\\left(\\zeta_n\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### So let's have a practical example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose we want to solve a differential equation:\n",
    "\n",
    "$$\\frac{dy(k; t)}{dt} = -ky(k; t).$$\n",
    "\n",
    "(k is random var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def RK4(f, ic, tspan, h):\n",
    "    t = [x * h for x in range(int((max(tspan) - min(tspan)) / h) + 1)]\n",
    "    y = [ic]\n",
    "    h2 = h / 2\n",
    "    for i in range(0, len(t)-1):\n",
    "        y1 = f(t[i], y[i])\n",
    "        y2 = f(t[i] + h2, y[i] + np.multiply(h2, y1))\n",
    "        y3 = f(t[i] + h2, y[i] + np.multiply(h2, y2))\n",
    "        y4 = f(t[i] + h, y[i] + np.multiply(h, y3))\n",
    "        y.append(y[i] + np.multiply(h/6, y1 + y4 + np.multiply(2, y2 + y3)))\n",
    "    return t, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "A = np.matrix([[-k]])\n",
    "ode = lambda t, x: A * x\n",
    "ic = np.matrix([1])\n",
    "t, y = RK4(ode, ic, [0, 10], .1)\n",
    "y1 = [np.asscalar(x) for x in y]\n",
    "plt.plot(t, y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now suppose we let $k$ be a random parameter with support $S$, pdf $f(k)$ and mean $\\bar{k}$.\n",
    "\n",
    "$$\\bar{y}(t) = y_0 e^{-\\bar{k}t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "stochastic mean (different from taking mean $\\bar{y}(t)$ and plugging it in), we actually have to solve for this:\n",
    "\n",
    "$$\\bar{y}(t) = y_0 \\int_S f(k)e^{-kt}\\, dk$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_dmc = []\n",
    "for k in range(1000):\n",
    "    B = np.matrix([[-np.random.uniform(0,1)]])\n",
    "    icb = np.matrix([1])\n",
    "    odeb = lambda t, x: B * x\n",
    "    t, y = RK4(odeb, icb, [0, 10], .01)\n",
    "    y_dmc.append([np.asscalar(x) for x in y])\n",
    "\n",
    "plt.plot(t, np.mean(y_dmc, axis=0))\n",
    "plt.plot(t, np.percentile(y_dmc, axis=0, q=95))\n",
    "plt.plot(t, np.percentile(y_dmc, axis=0, q=5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(t, np.mean(y_dmc, axis=0))\n",
    "\n",
    "B = np.matrix([[-0.5]])\n",
    "icb = np.matrix([1])\n",
    "odeb = lambda t, x: B * x\n",
    "t, y = RK4(odeb, icb, [0, 10], .01)\n",
    "y_detmean = [np.asscalar(x) for x in y]\n",
    "plt.plot(t, y_detmean, 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use Polynomial Chaos to make this easier.\n",
    "\n",
    "$$k = \\sum_{i=0}^P k_i \\Phi_i(\\zeta)$$\n",
    "$$y(t) = \\sum_{i=0}^P y_i(t) \\Phi_i(\\zeta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\\sum_{i=0}^P \\frac{dy_i}{dt} \\Phi_i(\\zeta) = -\\left(\\sum_{i=0}^P k_i \\Phi_i(\\zeta)\\right)\\left(\\sum_{i=0}^P y_i \\Phi_i(\\zeta)\\right)$$\n",
    "\n",
    "Perform the Galerkin projection and gather terms.\n",
    "\n",
    "$$\\frac{dy_l(t)}{dt} = -\\frac{1}{\\langle \\Phi_l^2(\\zeta)\\rangle} \\sum_{i=0}^P\\sum_{j=0}^P \\langle \\Phi_i \\Phi_j \\Phi_j \\rangle k_i y_j(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- $\\langle \\Phi_i \\Phi_j \\Phi_j \\rangle$: This is easily computed with Gauss-Hermite quadrature\n",
    "- $k_i$: We've already computed these!\n",
    "\n",
    "Result: we have a single $P^{\\text{th}}$-order linear ODE to solve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def triple_product(h1, h2, h3):\n",
    "    return lambda x : H.hermeval(x, H.hermemul(h1,\n",
    "                                               H.hermemul(h2, h3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "P = 5\n",
    "A = np.matrix(np.zeros((P,P)))\n",
    "m = P**3\n",
    "x, w = H.hermegauss(m)\n",
    "\n",
    "for l in range(P):\n",
    "    ip = sum([inner_product(Herm(l), Herm(l))(x[idx]) * w[idx] for idx in range(m)])\n",
    "    for j in range(P):\n",
    "        for i in range(P):\n",
    "            tp = sum([triple_product(Herm(i), Herm(j), Herm(l))(x[idx]) * w[idx] for idx in range(m)])\n",
    "            A[j,l] += - 1 / ip * tp * ki_uniform[i]\n",
    "\n",
    "ode = lambda t, x: A * x\n",
    "ic = np.matrix(np.zeros((P,1)))\n",
    "ic[0] = 1\n",
    "t, y = RK4(ode, ic, [0, 10], .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# compare upper, lower, mean of polynomially generated data to naive monte carlo\n",
    "plt.plot(t, np.mean(y_dmc, axis=0), 'b-')\n",
    "plt.plot(t, np.mean(y_dmc, axis=0)+3*np.var(y_dmc, axis=0), 'g-')\n",
    "plt.plot(t, np.mean(y_dmc, axis=0)-3*np.var(y_dmc, axis=0), 'r-')\n",
    "\n",
    "y_pc_mean = [x[0,0] for x in y]\n",
    "y_pc_var = [x[1,0]**2 for x in y]\n",
    "plt.plot(t, y_pc_mean, 'b--')\n",
    "plt.plot(t, np.add(y_pc_mean, np.multiply(3, y_pc_var)), 'g--')\n",
    "plt.plot(t, np.add(y_pc_mean, np.multiply(-3, y_pc_var)), 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y_pc = []\n",
    "for zeta in S[:500]:\n",
    "    y_pc.append([[H.hermeval(zeta, np.squeeze(x.tolist())) for i in range(P)] for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# compare polynomials: (they dont have good interpretation, except of mean)\n",
    "y_pc = [[[H.hermeval(zeta, np.squeeze(x.tolist())) for i in range(P)] for x in y] for zeta in S[:500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(t, np.mean(y_dmc, axis=0), 'b-')\n",
    "plt.plot(t, np.percentile(y_dmc, axis=0, q=95), 'g-')\n",
    "plt.plot(t, np.percentile(y_dmc, axis=0, q=5), 'r-')\n",
    "plt.plot(t,np.mean(y_pc, axis=0), 'b--')\n",
    "plt.plot(t, np.percentile(y_pc, axis=0, q=95), 'g--')\n",
    "plt.plot(t, np.percentile(y_pc, axis=0, q=5), 'r--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
