{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# \"Big Pandas\" - Dask from the Inside\n",
    "## Part 4 - Handling bigger data with Parquet\n",
    "### PyData Berlin tutorial, 30 June 2017\n",
    "### Stephen Simmons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Complete set of Python 3.6 imports used for these examples\n",
    "\n",
    "# Standard modules\n",
    "import io\n",
    "import logging\n",
    "import lzma\n",
    "import multiprocessing\n",
    "import os\n",
    "import ssl\n",
    "import sys\n",
    "import time\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# Third-party modules\n",
    "import fastparquet      # Needs python-snappy and llvmlite\n",
    "import graphviz         # To visualize Dask graphs \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil           # Memory stats\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import bokeh.io         # For Dask profile graphs\n",
    "import seaborn as sns   # For colormaps\n",
    "\n",
    "# Support multiple lines of output in each cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Don't wrap tables\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.width = 300\n",
    "\n",
    "# Show matplotlib and bokeh graphs inline in Jupyter notebook\n",
    "%matplotlib inline\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "print(sys.version)\n",
    "np.__version__, pd.__version__, dask.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loading a Dask Dataframe from multiple large csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set DIR_NAME to where original .xz flight data is stored. \n",
    "DIR_NAME = '/home/stephen/do-not-backup/data/usa-flights-otp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_otp_csv(start='2015-12', end='2016-03'):\n",
    "    \"\"\"\n",
    "    Dask DataFrame with BTS On-Time Performance flight data loaded from\n",
    "    multiple compressed monthly csv archives named 'flights-yyyy-mm.xz'.\n",
    "    \n",
    "    (Note pandas 0.19.2 drops the 'end' month. Reported as bug in GH#15886.)\n",
    "    \"\"\"\n",
    "    paths = [ os.path.join(DIR_NAME, 'flights-%s.xz' % dt.strftime('%Y-%m'))\n",
    "              for dt in pd.date_range(start, end, freq='M')]\n",
    "\n",
    "    cols = [\n",
    "        'FlightDate', 'Origin', 'Dest', 'OriginState', 'DestState',\n",
    "        'Carrier', 'FlightNum', 'TailNum', 'CRSDepTime', 'CRSArrTime',\n",
    "        'DepDelay', 'ArrDelay', 'Flights', 'Cancelled', 'Diverted',\n",
    "        ]\n",
    "\n",
    "    ddf = dd.read_csv(paths,\n",
    "                     dialect=\"excel\",\n",
    "                     header=0,\n",
    "                     compression='xz',\n",
    "                     usecols=cols,\n",
    "                     encoding='latin-1',  # Avoid unicode errors\n",
    "                     blocksize=None,      # Can't split compressed csv into blocks\n",
    "                     parse_dates=['FlightDate'],\n",
    "                     dtype={ 'FlightNum': str, }, # Don't want this as a number\n",
    "                     )\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf = load_otp_csv(start='2015-12', end='2016-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "task = ddf[['Carrier','Flights','Cancelled']].groupby('Carrier').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# More complex example - more source files, with 'select' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf = load_otp_csv(start='2016-01', end='2017-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task = ddf[ddf.FlightDate=='2016-01-24'][['Carrier','Flights','Cancelled']].groupby('Carrier').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf.npartitions\n",
    "ddf.divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We haven't given Dask any clues to optimize the computation.\n",
    "It doesn't know a priori that the source data is organized by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf2 = ddf.set_index('FlightDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf2.npartitions\n",
    "ddf2.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task2 = ddf2['2016-01-24'][['Carrier','Flights','Cancelled']].groupby('Carrier').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task2.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task2.compute()    # Oops!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The problem here is Dask has assumed our partitioned data was completely sorted.\n",
    "\n",
    "Remember slicing on labels can only return a single range if the column is monotonic.\n",
    "\n",
    "We can make this happen by forcing a sort on each partition as it gets processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sort_partition(df):\n",
    "    return df.set_index(df.FlightDate).sort_index()\n",
    "\n",
    "ddf3 = ddf.map_partitions(func=sort_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf3\n",
    "ddf3.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task3 = ddf3['2016-01-24'][['Carrier','Flights','Cancelled']].groupby('Carrier').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task3.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here, even though we sort the partitions, the Dask graph is having to process everything.\n",
    "We can help the graph optimizer by telling the top-level graph the Dask DataFrame's \n",
    "partitions are split on FlightDate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf4 = ddf3.set_index('FlightDate')\n",
    "ddf4\n",
    "ddf4.divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now the dependency graph looks very different .... the evaluator can jump directly \n",
    "to the correct monthly dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task4 = ddf4['2016-01-24'][['Carrier','Flights','Cancelled']].groupby('Carrier').sum()\n",
    "task4\n",
    "task4.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task4.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Parquet - a faster storage format than csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fastparquet.compression.compressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf4.to_parquet('flights.parq', compression='SNAPPY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What does this data look like...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import fastparquet\n",
    "pf = fastparquet.ParquetFile('flights.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ddf = dd.read_parquet('flights.parq', columns=['Carrier','Flights','Cancelled'])\n",
    "x = (ddf.loc['2016-01-18':'2016-01-28']\n",
    "         .reset_index()\n",
    "         .groupby(by=['Carrier','FlightDate'])\n",
    "         .sum()\n",
    "    )\n",
    "y = x['Cancelled']/x['Flights']*100\n",
    "out = y.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(out.unstack('FlightDate')\n",
    " .style\n",
    " .set_precision(2)\n",
    " .background_gradient(cmap=sns.light_palette(\"red\", as_cmap=True), \n",
    "                      high=0.4, low=0.2, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Visualizing Dask computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import dask.diagnostics.profile as profile\n",
    "from dask.diagnostics import ( ProgressBar, Profiler, \n",
    "                              ResourceProfiler, CacheProfiler )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf = dd.read_parquet('flights.parq')\n",
    "\n",
    "sum_cols = ['Carrier', 'Flights', 'Cancelled', 'Diverted']\n",
    "task = ddf[sum_cols].groupby('Carrier').sum()\n",
    "task['CancelledPct'] = task['Cancelled'] / task['Flights'] * 100\n",
    "task['DivertedPct'] = task['Diverted'] / task['Flights'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    out = task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import dask.diagnostics\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler\n",
    "from cachey import nbytes\n",
    "\n",
    "with ProgressBar():\n",
    "    with Profiler() as prof, \\\n",
    "            ResourceProfiler(dt=0.25) as rprof, \\\n",
    "                CacheProfiler(metric=nbytes) as cprof:\n",
    "        df = task.compute()\n",
    "dask.diagnostics.visualize([prof, rprof, cprof], save=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task._name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task._meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('\\n'.join(map(str,sorted(task.dask.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task.dask[('mul-0437b7b743e7c3e1b3c755647213950d', 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "task.dask[('dataframe-groupby-sum-combine-b65452308fa37f9d7c2918b0ae6daf88', 1, 0, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ddf.Carrier.dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
